{
    "mode": "train",
    "model_id": "google/t5-xl-lm-adapt",
    "dataset_lists": [
        "Program_Execution/task244_count_elements_in_set_union",
        "Program_Execution/task243_count_elements_in_set_intersection",
        "Program_Execution/task245_check_presence_in_set_intersection",
        "Question_Answering/task385_socialiqa_incorrect_answer_generation",
        "Story_Composition/task270_csrg_counterfactual_context_generation",
        "Program_Execution/task124_conala_pair_averages",
        "Explanation/task1369_healthfact_sentence_generation",
        "Question_Answering/task152_tomqa_find_location_easy_noise",
        "Question_Answering/task1380_quarel_correct_option_generation",
        "Program_Execution/task206_collatz_conjecture",
        "Question_Answering/task178_quartz_question_answering",
        "Story_Composition/task269_csrg_counterfactual_story_generation",
        "Question_Answering/task154_tomqa_find_location_hard_noise",
        "Question_Answering/task1378_quarel_correct_answer_generation",
        "Program_Execution/task755_find_longest_substring_and_replace_its_sorted_lowercase_version_in_both_lists",
        "Question_Answering/task580_socialiqa_answer_generation",
        "Question_Answering/task151_tomqa_find_location_easy_clean",
        "Question_Answering/task153_tomqa_find_location_hard_clean",
        "Program_Execution/task1088_array_of_products",
        "Question_Understanding/task046_miscellaneous_question_typing",
        "Wrong_Candidate_Generation/task1381_quarel_incorrect_option_generation",
        "Program_Execution/task122_conala_list_index_addition",
        "Wrong_Candidate_Generation/task1379_quarel_incorrect_answer_generation",
        "Program_Execution/task605_find_the_longest_common_subsequence_in_two_lists",
        "Text_Completion/task139_detoxifying-lms_classification_topicality",
        "Coherence_Classification/task065_timetravel_consistent_sentence_classification",
        "Misc./task1507_boolean_temporal_reasoning",
        "Named_Entity_Recognition/task1566_propara_structured_text_generation",
        "Question_Answering/task1565_triviaqa_classification",
        "Program_Execution/task205_remove_even_elements\",\"Program_Execution/task244_count_elements_in_set_union",
        "Program_Execution/task243_count_elements_in_set_intersection",
        "Program_Execution/task245_check_presence_in_set_intersection",
        "Question_Answering/task385_socialiqa_incorrect_answer_generation",
        "Story_Composition/task270_csrg_counterfactual_context_generation",
        "Program_Execution/task124_conala_pair_averages",
        "Explanation/task1369_healthfact_sentence_generation",
        "Question_Answering/task152_tomqa_find_location_easy_noise",
        "Question_Answering/task1380_quarel_correct_option_generation",
        "Program_Execution/task206_collatz_conjecture",
        "Question_Answering/task178_quartz_question_answering",
        "Story_Composition/task269_csrg_counterfactual_story_generation",
        "Question_Answering/task154_tomqa_find_location_hard_noise",
        "Question_Answering/task1378_quarel_correct_answer_generation",
        "Program_Execution/task755_find_longest_substring_and_replace_its_sorted_lowercase_version_in_both_lists",
        "Question_Answering/task580_socialiqa_answer_generation",
        "Question_Answering/task151_tomqa_find_location_easy_clean",
        "Question_Answering/task153_tomqa_find_location_hard_clean",
        "Program_Execution/task1088_array_of_products",
        "Question_Understanding/task046_miscellaneous_question_typing",
        "Wrong_Candidate_Generation/task1381_quarel_incorrect_option_generation",
        "Program_Execution/task122_conala_list_index_addition",
        "Wrong_Candidate_Generation/task1379_quarel_incorrect_answer_generation",
        "Program_Execution/task605_find_the_longest_common_subsequence_in_two_lists",
        "Text_Completion/task139_detoxifying-lms_classification_topicality",
        "Coherence_Classification/task065_timetravel_consistent_sentence_classification",
        "Misc./task1507_boolean_temporal_reasoning",
        "Named_Entity_Recognition/task1566_propara_structured_text_generation",
        "Question_Answering/task1565_triviaqa_classification",
        "Program_Execution/task205_remove_even_elements",
        "Question_Understanding/task027_drop_answer_type_generation",
        "Program_Execution/task093_conala_normalize_lists",
        "Question_Generation/task191_hotpotqa_question_generation",
        "Information_Extraction/task1568_propara_classification",
        "Question_Answering/task582_naturalquestion_answer_generation",
        "Explanation/task223_quartz_explanation_generation",
        "Question_Generation/task1567_propara_question_generation",
        "Question_Answering/task1286_openbookqa_question_answering",
        "Question_Understanding/task248_dream_classification",
        "Question_Answering/task490_mwsc_options_generation",
        "Question_Answering/task028_drop_answer_generation"
    ],
    "epochs": 3,
    "output_dir": "out/data_to_text_task1407_top70",
    "per_device_train_batch_size": 16,
    "gradient_accumulation_steps": 1,
    "lr": 5e-05,
    "deepspeed": "deepspeed_configs/z2_bf16_no_optim.json",
    "n_gpu": 16
}